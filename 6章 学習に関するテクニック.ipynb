{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パラメータの最適化は難しい！  \n",
    "そして確率的勾配降下法はナイーブなので，もう少しスマートな方法を使ってみよう！  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確率的勾配降下法は簡単に実装すると以下のようになる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGDを使ってNNのパラメータの更新をする疑似コードを書くと次のようになる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "network = TwoLayerNet(...)\n",
    "optimizer = SGD()\n",
    "\n",
    "for i in range(10000):\n",
    "    ...\n",
    "    x_batch, t_batch = get_mini_batch(...)\n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "    params = network.params\n",
    "    optimizer.update(params, grads)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGDは最適解に行くまでが非効率なことがある．  \n",
    "ジグザグの動きになって，移動距離が長くなる．  \n",
    "それを軽減するのが次のMomentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ v \\leftarrow \\alpha v - \\eta \\frac{\\partial L}{\\partial W} $$\n",
    "$$ W \\leftarrow W + v $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "速度の減衰を考慮する更新式．  \n",
    "vは速度を，αは減速率を示す．  \n",
    "この最適化手法をクラスであらわすと以下のようになる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        # 前の速度を使うので，vに速度を記録しておく\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for key, val in params.items():\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "        \n",
    "        for key in params.keys():\n",
    "            self.v[key] = self.momentum * self.v[key] - self.lr * self.grads[key]\n",
    "            params[key] += self.v[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "反動を考慮するので，ジグザグの動きを軽減できる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習係数を減衰させる  \n",
    "全部の学習係数を減衰させるのではなく，一つ一つのパラメータに対して学習係数を減衰させていくのがAdaGrad  \n",
    "つまりAdaptive Gradientのこと  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ h \\leftarrow h + \\frac{\\partial L}{\\partial W} \\odot \\frac{\\partial L}{\\partial W} $$\n",
    "$$ W \\leftarrow W - \\eta \\frac{1}{\\sqrt{h}} \\frac{\\partial L}{\\partial W} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hは，学習が進むほど大きくなる．$\\frac{1}{\\sqrt{h}}$が更新時にかかるので，更新される重みは学習が進むほど小さくなっていく  \n",
    "\n",
    "無限に学習を行うと更新量が0になってしまう．  \n",
    "これを改善した手法にRMSPropがある．こちらは，新しい勾配の情報が大きく反映されるように加算していく．  \n",
    "指数関数的に過去の勾配のスケールを減少させる「指数移動平均」を用いる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key, val in params.items():\n",
    "                self.h[key] = np.zeros_like(val)\n",
    "        \n",
    "        for key in params.keys():\n",
    "            self.h += grads[key] * grads[key]\n",
    "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7) # ゼロ除算を防ぐ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "めっちゃ効率的に最小値に向かう！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaGrad + Momentum  \n",
    "3つのハイパーパラメータを使用した複雑めな手法．多くの場合うまくいく設定値がある．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上4つの手法を紹介したが，どれが一番適しているかは，解くべき問題によって異なるので，いろいろ試してみるのがよい．  \n",
    "最近はAdamを使う研究者が多いらしい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNISTデータセットに対して，以上の更新手法を比較してみると，SGDよりも他の手法が早く，  \n",
    "特にAdaGradはやや他の手法より早い．最終的な認識性能も高くなる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重みの初期値"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重みの初期値がすべて0なのはよくない．  \n",
    "順伝搬で次の層に0が渡されれば，逆伝搬時に返ってくる値が全て0になってしまう．  \n",
    "すると，せっかくたくさんのパラメータを持つ意味がなくなってしまう．  \n",
    "そのため，重みの対称的な構造を崩す，すなわち重複する値を持たないようにすることが必要．  \n",
    "従って，ランダムな初期値が必要になる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "活性化関数を通った後の出力データの分布，アクティベーション分布を観察してみよう．  \n",
    "5層NN，活性化関数にシグモイド関数を使ったものに，ランダムな入力データを流し，ヒストグラムで描画してみる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験プログラムの一部\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "x = np.random.randn(1000, 100) # 1000個のデータ\n",
    "node_num = 100\n",
    "hidden_layer_size = 5\n",
    "activations = {}\n",
    "\n",
    "for i in range(hidden_layer_size):\n",
    "    if i != 0:\n",
    "        x = activations[i-1]\n",
    "    \n",
    "    w = np.random.randn(node_num, node_num) * 1 # 掛けた値が標準偏差になる\n",
    "    \n",
    "    z = np.dot(x, w)\n",
    "    a = sigmoid(z)\n",
    "    activations[i] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のコードは標準偏差1のガウス分布を使って重みを生成しているが，この標準偏差を変えたらどうなるだろうか？  \n",
    "\n",
    "標準偏差1のとき，どの層も出力は0か1付近に固まることが分かる．  \n",
    "0と1に固まった出力は，次の層の出力も同じように0と1に固めてしまう．  \n",
    "この問題を**勾配消失**と呼び，層が深くなるほど深刻になる．  \n",
    "\n",
    "標準偏差0.01のとき，アクティベーションは0.5に固まる．これもよくない．  \n",
    "これはすなわち，「表現力の制限」という問題になっている．  \n",
    "\n",
    "各層のアクティベーションの分布は，適度な広がりを持つことが求められる．  \n",
    "そのほうが，学習が効率的に行える．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に，Xavierの初期値を使ってみる．  \n",
    "これは，$\\frac{1}{\\sqrt{n}}$の標準偏差を持つものである．nはノードの数である．  \n",
    "この初期値を使うと，前よりも適度な広がりを持つアクティベーション分布になる．\n",
    "\n",
    "上位の層になるほどいびつな形になるが，活性化関数に，似た形のtanhを使うと改善される．  \n",
    "なお，活性化関数に用いる関数は，原点対象であることが望ましい．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xavierの初期値は，左右対称で中央付近が線形関数としてみなせるSigmoid関数やtanh関数に適している．  \n",
    "一方，初期値を$\\sqrt{\\frac{2}{n}}$とする「Heの初期値」は，ReLUに特化している．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNISTデータセットはで試してみると，  \n",
    "標準偏差0.01 ＝＞ 学習全然進まない  \n",
    "Xavierの初期値＋Sigmoid ＝＞ 学習よく進む  \n",
    "Heの初期値＋ReLU ＝＞ Xavierよりも学習良く進む"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結論：初期値は大事！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization  \n",
    "各層のアクティベーションの分布を強制的に調整しようとする  \n",
    "\n",
    "- 学習を早く進行させられる\n",
    "- 初期値にあまり依存しない\n",
    "- 過学習を抑制する\n",
    "\n",
    "データ分布の正規化を行う，「Batch Normレイヤ」をAffineレイヤとReLUレイヤの間に挿入する．\n",
    "Batch Normレイヤはデータの分布を平均0，分散1になるよう調整する．\n",
    "$$\\hat{x_i} \\leftarrow \\frac{x_i - \\mu_B}{\\sqrt{\\sigma^2_B + \\epsilon}}$$\n",
    "\n",
    "さらに，正規化されたデータに対して固有のスケール(傾き)とシフト(切片)で変換を行う．  \n",
    "$$y_i \\leftarrow \\gamma \\hat{x_i} + \\beta$$\n",
    "\n",
    "$\\gamma = 1, \\beta = 0$からスタートして，学習の進度に適した値に調整される． \n",
    "\n",
    "逆伝搬はちょいめんどい．  \n",
    "\n",
    "実際動作させてみると，BatchNormを使った方が早く，精度もいい．  \n",
    "これにより，初期値にロバスト(あまり依存しない)学習を実現できる．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 過学習  \n",
    "訓練データだけに適応しすぎ，他のデータにうまく対応できなくなること"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 過学習の原因  \n",
    "- モデルのパラメータが多く，表現力が高い．\n",
    "- 訓練データが少ない．  \n",
    "\n",
    "学習データを60000から300にしてみる．  \n",
    "すると，100エポックを過ぎたあたりから，訓練データにはほぼ100%適合し，テストデータには60%ほどで頭打ちになるという結果になる．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 過学習の抑制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weight decay  \n",
    "荷重減衰  \n",
    "大きな重みをもつことにペナルティを課す  \n",
    "過学習は重みが大きくなることによって発生しやすい  \n",
    "例えば，L2ノルム(重さの2乗和)を損失関数に加えることで正則化を行う．\n",
    "$$ Loss(t) + \\frac{1}{2} \\lambda W^2 $$\n",
    "$\\lambda$はペナルティの強さ，$ \\frac{1}{2} $は微分の結果を調整するための値, tは学習のラウンド  \n",
    "これより，逆伝搬の時には$\\lambda W$が加算される．  \n",
    "  \n",
    "結果，訓練データとテストデータの認識精度の隔たりを軽減できる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout  \n",
    "ニューロンをランダムに消して学習を行う  \n",
    "\n",
    "これもまた，訓練データとテストデータの認識精度の隔たりを軽減できる．  \n",
    "\n",
    "これは，アンサンブル学習を疑似的に一つのネットワークで実現しているといえる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメータの検証  \n",
    "パラメータ： 重みやバイアス  \n",
    "ハイパーパラメータ： ニューロン数，バッチサイズ，学習係数，Weight decayなど  \n",
    "\n",
    "テストデータを使ってハイパーパラメータの値を調整してはいけない．  \n",
    "テストデータに対して過学習することもあり得るから．  \n",
    "\n",
    "よって，テストデータとは別にハイパーパラメータ調整用の「検証データ」と呼ばれるものが必要になる．  \n",
    "訓練データの中から20%を分離したりする．データが並んでたりするので分離前にシャッフルすること．  \n",
    "\n",
    "1. ハイパーパラメータの範囲をざっくりと設定する．\n",
    "    - 0.001 ~ 10^3など\n",
    "1. その範囲から，ランダムに値をサンプリングする．\n",
    "1. その値を使って学習を行い，検証データで認識精度を評価する．\n",
    "1. ステップ2, 3を100回ほど繰り返し，それらの認識精度の結果がよかったものを参考に，ハイパーパラメータの範囲を狭めていく．\n",
    "\n",
    "ベイズの定理を使って効率よく最適化を行う`ベイズ最適化`なども使える．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ  \n",
    "- パラメータの更新方法\n",
    "    - SGD: 確率的勾配降下法，ランダムにミニバッチを生成し，学習\n",
    "        - ナイーブ，解にジグザグに向かう\n",
    "    - Momentum: 速度の減衰を考慮に入れた更新式を使う\n",
    "        - SGDよりは早く解に向かう\n",
    "    - AdaGrad: Adaptive Gradient, 一つ一つのパラメータに対して学習が進むたびに学習係数を減衰させていく\n",
    "        - なかなか効率的\n",
    "    - Adam: AdaGrad + Momentum\n",
    "        - 3つのハイパーパラメータを持ち，なかなか複雑だが，これが最近は多く使われている．\n",
    "  \n",
    "- 重みの初期値の与え方\n",
    "    - 勾配消失問題: どの層も出力が0, 1に固まると，次の層の出力も0, 1になってしまい，いい結果が得られない問題．\n",
    "    - Xavierの初期値: $\\frac{1}{\\sqrt{n}}$の標準偏差を持つ\n",
    "        - tanhやSigmoid，恒等関数のような原点対象の関数に強い\n",
    "    - Heの初期値: 初期値を$\\sqrt{\\frac{2}{n}}$とする\n",
    "        - ReLUに特化\n",
    "      \n",
    "- Batch Normalization\n",
    "    - 活性化関数の前後で，出力の平均を0，分散を1にすることで，学習を早め，精度を高め，過学習を防ぐ．\n",
    "  \n",
    "- 過学習抑制\n",
    "    - Weight decay: L2ノルムなどの正則化項を加える\n",
    "    - Dropout: ランダムにニューロンを消去し，疑似アンサンブル学習\n",
    "  \n",
    "- ハイパーパラメータの探索\n",
    "    - 検証データを使って認識精度が良かったときのパラメータの範囲を観察し，狭めていく．\n",
    "    - ベイズ最適化"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
