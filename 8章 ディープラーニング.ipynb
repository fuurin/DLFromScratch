{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ディープラーニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この章は読み物  \n",
    "気になったワードをメモっていく"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augumentation(データ拡張)  \n",
    "回転や縦方向の移動といった微小な変化を与えて画像の枚数を増やすこと  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ILSVRC  \n",
    "大規模画像認識コンペ  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5,5)のフィルタは，(3,3)のフィルタを2回かければカバーできる  \n",
    "前者のパラメータ数は$ 5 * 5 = 25 $, 後者は$ 3 * 3 * 2 = 18 $  \n",
    "だから層を深くした方が一般的にいい結果になる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "受容野  \n",
    "ニューロンに変化を生じさせる局所的な空間領域  \n",
    "層を増やした方がこれが広くなる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "層を深くした方が活性化関数がかかる機会が多くなり，非線形の力が強まるので，表現力が向上する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG  \n",
    "(3,3)のフィルタを使った畳み込みをひたすら行うCNN  \n",
    "2014コンペの2位ではあったが，シンプルなのでVGGベースのネットワークは技術者が好んで使う．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GoogLeNet  \n",
    "2014年優勝  \n",
    "インセプション構造: ネットワークに「幅」がある  \n",
    "(1,1)のフィルタの畳み込み層を多くの場所で使用し，チャンネル方向にサイズを減らしてパラメータの削減や処理の高速化を行う．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet  \n",
    "層を深くしても学習をうまくいかせるために，「スキップ構造」を採用\n",
    "いくつかの層を飛ばすことができる．  \n",
    "これによって逆伝搬の際信号が減衰することがない．  \n",
    "勾配消失問題を軽減できると期待できる  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "転移学習\n",
    "別のニューラルネットワークの重みデータを流用し，再学習(fine tuning)を行わせること．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込み層での計算を高速化するのが大事"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUコンピューティング  \n",
    "CPUで40日以上かかる計算を6日まで短縮できる  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUDA  \n",
    "NVIDIAのGPUコンピューティング向けの統合開発環境  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cuDNN  \n",
    "CUDAの上で動作するライブラリでディープラーニング用に最適化された関数などが実装されている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分散学習  \n",
    "複数のGPUやマシンで学習を行う．  \n",
    "TensorflowやCNTKは分散学習を最重視して開発されている  \n",
    "100個GPUを使えば，56倍の高速化が可能  \n",
    "しかし，どのように計算を分散させるかは難しい問題．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ディープラーニングでは数値精度のビット数をそこまで必要としない．  \n",
    "これは，ニューラルネットワークのロバスト性による効果である．  \n",
    "16bitで十分なことがわかっている．  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ディープラーニングの応用例  \n",
    "- 物体検出  \n",
    "    - R-CNN オブジェクトらしい領域を切り出し，それぞれをCNN  \n",
    "    - Faster R-CNN 候補領域抽出もCNNで行う  \n",
    "- セグメンテーション  \n",
    "    - FCN Fully Convolutional Network\n",
    "- 画像キャプション  \n",
    "    - NIC: ディープなCNN ＋ RNN（Recurrent Neural Network）\n",
    "    - マルチモーダル処理： 画像 ＋ 自然言語処理 といった複数の種類の情報を組み合わせて処理すること  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ディープラーニングの未来\n",
    "- 画像スタイル変換: ゴッホの絵っぽい画像に仕立て上げる\n",
    "    - スタイル行列をスタイル画像から作成し，ずれを小さくするように学習する  \n",
    "- 画像生成  \n",
    "    - Deep Convolutional Generative Adversarial Network\n",
    "        - GeneratorとDescriminatorが判定ゲームするあれ\n",
    "        - 教師なし学習に分類される\n",
    "- 自動運転\n",
    "    - SegNet 走路環境の認識\n",
    "- Deep Q-Network（強化学習）\n",
    "    - 強化学習: 環境からエージェントが何らかの報酬を得る．\n",
    "    - Q学習: 最適行動価値関数を近似するのにCNNを用いる．\n",
    "    - ゲームの画像を与えるだけなのでどんなゲームにも応用でき，実際に人間を上回る動作を示している．\n",
    "    - AlphaGo: Deep Mind社によって開発\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
